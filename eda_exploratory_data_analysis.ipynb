{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando diretórios:\n",
      "/app existe: True\n",
      "/app/datalake existe: True\n",
      "/app/datalake/silver existe: True\n",
      "/app/datalake/silver/treino existe: True\n",
      "/app/datalake/silver/itens existe: True\n",
      "\n",
      "Conteúdo de /app/datalake/silver:\n",
      "['itens', 'treino']\n"
     ]
    }
   ],
   "source": [
    "# Check directories and files\n",
    "import os\n",
    "\n",
    "print(\"Verificando diretórios:\")\n",
    "print(\"/app existe:\", os.path.exists(\"/app\"))\n",
    "print(\"/app/datalake existe:\", os.path.exists(\"/app/datalake\"))\n",
    "print(\"/app/datalake/silver existe:\", os.path.exists(\"/app/datalake/silver\"))\n",
    "print(\"/app/datalake/silver/treino existe:\", os.path.exists(\"/app/datalake/silver/treino\"))\n",
    "print(\"/app/datalake/silver/itens existe:\", os.path.exists(\"/app/datalake/silver/itens\"))\n",
    "\n",
    "if os.path.exists(\"/app/datalake/silver\"):\n",
    "    print(\"\\nConteúdo de /app/datalake/silver:\")\n",
    "    print(os.listdir(\"/app/datalake/silver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Silver Data Exploration\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.default.parallelism\", \"12\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\") \\\n",
    "    .config(\"spark.locality.wait\", \"0s\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data (note the correct path for mapped volume)\n",
    "treino = spark.read \\\n",
    "    .option(\"mergeSchema\", \"false\") \\\n",
    "    .parquet(\"/app/datalake/silver/treino\") \\\n",
    "    .coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = spark.read \\\n",
    "    .option(\"mergeSchema\", \"false\") \\\n",
    "    .parquet(\"/app/datalake/silver/itens\") \\\n",
    "    .coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary tables for SQL\n",
    "treino.createOrReplaceTempView(\"tab_treino\")\n",
    "itens.createOrReplaceTempView(\"tab_itens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros em treino: 8123951\n",
      "Número de registros em itens: 255603\n",
      "\n",
      "Schema dos dados de treino:\n",
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- userType: string (nullable = true)\n",
      " |-- history: string (nullable = true)\n",
      " |-- timestampHistory: string (nullable = true)\n",
      " |-- numberOfClicksHistory: integer (nullable = true)\n",
      " |-- timeOnPageHistory: integer (nullable = true)\n",
      " |-- scrollPercentageHistory: float (nullable = true)\n",
      " |-- pageVisitsCountHistory: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n",
      "\n",
      "Schema dos dados de itens:\n",
      "root\n",
      " |-- page: string (nullable = true)\n",
      " |-- issued: timestamp (nullable = true)\n",
      " |-- modified: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- caption: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show record counts\n",
    "print(\"Número de registros em treino:\", treino.count())\n",
    "print(\"Número de registros em itens:\", itens.count())\n",
    "\n",
    "# Show data schema\n",
    "print(\"\\nSchema dos dados de treino:\")\n",
    "treino.printSchema()\n",
    "\n",
    "print(\"\\nSchema dos dados de itens:\")\n",
    "itens.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|min_timestamp      |max_timestamp      |\n",
      "+-------------------+-------------------+\n",
      "|2022-07-01 03:00:00|2022-08-15 02:59:47|\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query\n",
    "results = spark.sql(\"\"\"\n",
    "    SELECT min(timestampHistory) as min_timestamp, \n",
    "           max(timestampHistory) as max_timestamp\n",
    "    FROM tab_treino\n",
    "\"\"\")\n",
    "\n",
    "results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuição de userType:\n",
      "+----------+-------+\n",
      "|  userType|  count|\n",
      "+----------+-------+\n",
      "|    Logged|3676649|\n",
      "|Non-Logged|4447302|\n",
      "+----------+-------+\n",
      "\n",
      "\n",
      "Estatísticas de timeOnPageHistory:\n",
      "+-------+-----------------+\n",
      "|summary|timeOnPageHistory|\n",
      "+-------+-----------------+\n",
      "|  count|          8123951|\n",
      "|   mean|88768.68892008334|\n",
      "| stddev|113932.1803580999|\n",
      "|    min|             5000|\n",
      "|    max|         46033049|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic analysis\n",
    "print(\"\\nDistribuição de userType:\")\n",
    "treino.groupBy(\"userType\").count().show()\n",
    "\n",
    "print(\"\\nEstatísticas de timeOnPageHistory:\")\n",
    "treino.select(\"timeOnPageHistory\").describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
