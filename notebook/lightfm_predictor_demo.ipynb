{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM Predictor Demo\n",
    "\n",
    "This notebook demonstrates how to use the LightFMPredictor class to generate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class SparkSessionFactory:\n",
    "    def create_spark_session(self, app_name: str):\n",
    "        print(\"Initializing Spark Session...\")\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(app_name) \\\n",
    "            .config(\"spark.driver.memory\", \"8g\") \\\n",
    "            .config(\"spark.executor.memory\", \"8g\") \\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "            .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "            .config(\"spark.sql.files.maxPartitionBytes\", \"128m\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.host\", \"localhost\") \\\n",
    "            .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "            .config(\"spark.network.timeout\", \"800s\") \\\n",
    "            .config(\"spark.cleaner.periodicGC.interval\", \"1min\") \\\n",
    "            .config(\"spark.sql.files.openCostInBytes\", \"1048576\") \\\n",
    "            .config(\"spark.sql.broadcastTimeout\", \"300\") \\\n",
    "            .config(\"spark.sql.parquet.filterPushdown\", \"true\") \\\n",
    "            .config(\"spark.sql.inMemoryColumnarStorage.compressed\", \"true\") \\\n",
    "            .config(\"spark.sql.parquet.writeLegacyFormat\", \"false\") \\\n",
    "            .config(\"spark.default.parallelism\", \"10\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        spark.sparkContext.setLogLevel(\"WARN\")\n",
    "        print(\"Spark Session initialized.\")\n",
    "        return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lightfm import LightFM\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "from pyspark.sql.functions import col, udf, array\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, StructType, StructField\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class LightFMPredictor:\n",
    "    def __init__(self, model_path: str, user_features_path: str, item_features_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the predictor\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to saved LightFM model\n",
    "            user_features_path: Path to user features parquet\n",
    "            item_features_path: Path to item features parquet\n",
    "        \"\"\"\n",
    "        self.spark = SparkSessionFactory().create_spark_session(\"LightFM Predictor\")\n",
    "        self.model = self._load_model(model_path)\n",
    "        self.user_features_path = user_features_path\n",
    "        self.item_features_path = item_features_path\n",
    "        self.user_features = None\n",
    "        self.item_features = None\n",
    "        self.item_ids = None\n",
    "        self._load_features()\n",
    "\n",
    "    def _load_model(self, model_path: str) -> LightFM:\n",
    "        \"\"\"Load the trained LightFM model\"\"\"\n",
    "        logger.info(f\"Loading model from {model_path}\")\n",
    "        try:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _load_features(self):\n",
    "        \"\"\"Load and prepare user and item features\"\"\"\n",
    "        logger.info(\"Loading features...\")\n",
    "        \n",
    "        try:\n",
    "            # Load user features\n",
    "            user_features_df = self.spark.read.parquet(self.user_features_path)\n",
    "            self.user_features = self._convert_features_to_sparse(user_features_df, \"user_features\")\n",
    "            \n",
    "            # Load item features\n",
    "            item_features_df = self.spark.read.parquet(self.item_features_path)\n",
    "            self.item_features = self._convert_features_to_sparse(item_features_df, \"features\")\n",
    "            \n",
    "            # Store item IDs for mapping predictions back to items\n",
    "            self.item_ids = [row.page for row in item_features_df.select(\"page\").collect()]\n",
    "            \n",
    "            logger.info(\"Features loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading features: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _convert_features_to_sparse(self, df, feature_col):\n",
    "        \"\"\"Convert DataFrame features to sparse matrix\"\"\"\n",
    "        features_list = [row[feature_col].toArray() for row in df.select(feature_col).collect()]\n",
    "        features_array = np.array(features_list)\n",
    "        if features_array.ndim > 2:\n",
    "            features_array = features_array.reshape(features_array.shape[0], -1)\n",
    "        return sp.csr_matrix(features_array)\n",
    "\n",
    "    def predict_for_user(self, user_id: str, n_items: int = 10) -> list:\n",
    "        \"\"\"\n",
    "        Generate recommendations for a single user\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID to generate predictions for\n",
    "            n_items: Number of items to recommend\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples (item_id, score)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get user features\n",
    "            user_df = self.spark.read.parquet(self.user_features_path).filter(col(\"userId\") == user_id)\n",
    "            if user_df.count() == 0:\n",
    "                logger.warning(f\"User {user_id} not found in features\")\n",
    "                return []\n",
    "\n",
    "            user_features = self._convert_features_to_sparse(user_df, \"user_features\")\n",
    "            \n",
    "            # Generate predictions for all items\n",
    "            n_items_total = len(self.item_ids)\n",
    "            user_ids = np.repeat(0, n_items_total)  # Create array of same length as items\n",
    "            item_ids = np.arange(n_items_total)\n",
    "            \n",
    "            # Generate predictions\n",
    "            scores = self.model.predict(\n",
    "                user_ids=user_ids,\n",
    "                item_ids=item_ids,\n",
    "                user_features=user_features,\n",
    "                item_features=self.item_features\n",
    "            )\n",
    "\n",
    "            # Normalize scores to [0,1] range\n",
    "            scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "            \n",
    "            # Get top N items\n",
    "            top_items_idx = np.argsort(-scores)[:n_items]\n",
    "            recommendations = [(self.item_ids[idx], float(scores[idx])) for idx in top_items_idx]\n",
    "            \n",
    "            return recommendations\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating predictions for user {user_id}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def batch_predict(self, user_ids: list, n_items: int = 10) -> dict:\n",
    "        \"\"\"\n",
    "        Generate predictions for multiple users\n",
    "        \n",
    "        Args:\n",
    "            user_ids: List of user IDs\n",
    "            n_items: Number of items to recommend per user\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping user IDs to their recommendations\n",
    "        \"\"\"\n",
    "        recommendations = {}\n",
    "        for user_id in user_ids:\n",
    "            recommendations[user_id] = self.predict_for_user(user_id, n_items)\n",
    "        return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Predictor\n",
    "\n",
    "First, we'll create an instance of the LightFMPredictor by providing paths to the model and feature files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark Session...\n",
      "Spark Session initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths to required files\n",
    "MODEL_PATH = '../models/lightfm_model.pkl'\n",
    "USER_FEATURES_PATH = '../datalake/gold/lightfm_user_features/user_features.parquet'\n",
    "ITEM_FEATURES_PATH = '../datalake/gold/lightfm_item_features/item_features.parquet'\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "            raise FileNotFoundError(f\"Model file not found at path: {MODEL_PATH}\")\n",
    "\n",
    "if not os.path.exists(USER_FEATURES_PATH):\n",
    "            raise FileNotFoundError(f\"Model file not found at path: {USER_FEATURES_PATH}\")\n",
    "\n",
    "if not os.path.exists(ITEM_FEATURES_PATH):\n",
    "            raise FileNotFoundError(f\"Model file not found at path: {ITEM_FEATURES_PATH}\")\n",
    "\n",
    "# Initialize the predictor\n",
    "predictor = LightFMPredictor(\n",
    "    model_path=MODEL_PATH,\n",
    "    user_features_path=USER_FEATURES_PATH,\n",
    "    item_features_path=ITEM_FEATURES_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Recommendations for a Single User\n",
    "\n",
    "Let's generate recommendations for a single user and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4b901419051126488b9:\n",
      "Item: 6a52871e-1a78-4575-8999-765c98d6aafc, Score: 1.0000\n",
      "Item: 92875985-34de-4549-9dc8-0735ea34d972, Score: 0.9969\n",
      "Item: a47afb19-8d6f-4550-ad38-9b64b754ab3f, Score: 0.9539\n",
      "Item: f7a88bf3-c3c3-4b37-b51d-e7eabe570fce, Score: 0.9503\n",
      "Item: 05d4ac1a-822b-4751-a9c4-0a7b1fd5cdd3, Score: 0.9461\n",
      "Item: 2f478e54-eedc-44d3-b1d9-da6a5c28a800, Score: 0.9402\n",
      "Item: e1462137-046f-458d-bad2-85f4cf66b723, Score: 0.9365\n",
      "Item: 8bf71ac1-9412-4df7-87e7-10d5c55236e4, Score: 0.9265\n",
      "Item: b2f3b10f-6e2f-4cd8-9554-c0de2ada1c81, Score: 0.9245\n",
      "Item: 3343e1a0-133e-4012-89f5-467793780d25, Score: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# Example user ID - replace with an actual user ID from your dataset\n",
    "user_id = \"e25fbee3a42d45a2914f9b061df3386b2ded2d8cc1f3d4b901419051126488b9\"\n",
    "\n",
    "# Get recommendations for the user\n",
    "recommendations = predictor.predict_for_user(user_id, n_items=10)\n",
    "\n",
    "print(f\"Top 5 recommendations for user {user_id}:\")\n",
    "for item_id, score in recommendations:\n",
    "    print(f\"Item: {item_id}, Score: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
